Lab 01

Se puede concluir bastante de esta práctica, ya que su objetivo fue conocer las propiedades de la trajeta gráfica o GPU que cada máquina posee. Una de estas conlcusiones a las que llego es que puedes manipular o ajustar las propiedades maxThreadsPerBlock y maxBlocksPerMultiProcessor, mientras que la multiplicación de estos números sea menor o igual a la propiedad maxThreadsPerMultiProcessor. Además, resultó que los bloques y el grid son trdimensionales, lo cual por fin me explicó muchas dudas de la sintaxis que había visto en códigos de ejemplo donde se llama un kernel y se esepcificaban unos parámetros enteros que ahora entiendo qué significan. Al conocer el Major Property y la Minor Property me hicieron mucho sentido ahora los problemas que tuve al instalar CUDA inicialmente, pues para configurar el entorno de trabajo, conocer estas propiedades es fundamental.

Lab 02

Se concluye al final de esta práctica que efectivamente la memoria del CPU y la memoria del GPU está separada por completo, lo que tiene una no lo tiene la otra. Y de ahí salen las funciones de CUDA para copiar variables o memoria desde el Host al Device, por ejemplo. Al principio, no le vi mucho sentido al usar los tipos de transferencia conocidos como HostToHost o DeviceToDevice, pues si se trata de acciones entre memoria común, pues se aplican las normas de programación simple (ciclos) para copiar memoria o asignarla. Sin embargo, jamás hubiera pensado que estas funciones de CUDA evitan el uso de ciclos para copiar memoria de arreglos o matrices, lo cual optimiza el código y nos quita esa tarea engorrosa de programar ciclos hasta triples cada que queremos copiar información desde estructuras de datos. Me pareció bastante productiva esta práctica para ejemplificar cada tipo de transferencia de datos.